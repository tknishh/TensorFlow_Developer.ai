{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlowDeveloper.ai",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNnFhZvWczUQ9DhpkAxbliv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tknishh/TensorFlow_Developer.ai/blob/main/TensorFlowDeveloper_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "C1W1\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "oL_ZorzeHR0D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsr8CQot0YIy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([keras.layers.Dense(units=1,input_shape=[1])])"
      ],
      "metadata": {
        "id": "-esj9-s13QwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='sgd', loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "1FQ7b16lE2eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
      ],
      "metadata": {
        "id": "HTGJ8bijFO-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(xs,ys,epochs=400)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjV8lWExGH3y",
        "outputId": "d88606a6-3279-4ce1-9cce-8a2c0221dfb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "1/1 [==============================] - 1s 502ms/step - loss: 5.2392\n",
            "Epoch 2/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.2987\n",
            "Epoch 3/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5551\n",
            "Epoch 4/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.9665\n",
            "Epoch 5/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.4999\n",
            "Epoch 6/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1294\n",
            "Epoch 7/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8346\n",
            "Epoch 8/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5994\n",
            "Epoch 9/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4112\n",
            "Epoch 10/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2599\n",
            "Epoch 11/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1378\n",
            "Epoch 12/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0388\n",
            "Epoch 13/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9579\n",
            "Epoch 14/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8914\n",
            "Epoch 15/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8362\n",
            "Epoch 16/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7900\n",
            "Epoch 17/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7510\n",
            "Epoch 18/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7176\n",
            "Epoch 19/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6888\n",
            "Epoch 20/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6635\n",
            "Epoch 21/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6411\n",
            "Epoch 22/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6211\n",
            "Epoch 23/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6029\n",
            "Epoch 24/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5863\n",
            "Epoch 25/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5709\n",
            "Epoch 26/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5565\n",
            "Epoch 27/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5430\n",
            "Epoch 28/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5302\n",
            "Epoch 29/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5181\n",
            "Epoch 30/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5064\n",
            "Epoch 31/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4952\n",
            "Epoch 32/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4844\n",
            "Epoch 33/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4740\n",
            "Epoch 34/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4639\n",
            "Epoch 35/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4540\n",
            "Epoch 36/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4445\n",
            "Epoch 37/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4351\n",
            "Epoch 38/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4261\n",
            "Epoch 39/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4172\n",
            "Epoch 40/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4085\n",
            "Epoch 41/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4001\n",
            "Epoch 42/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3918\n",
            "Epoch 43/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3837\n",
            "Epoch 44/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3758\n",
            "Epoch 45/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3680\n",
            "Epoch 46/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3605\n",
            "Epoch 47/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3530\n",
            "Epoch 48/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3458\n",
            "Epoch 49/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3387\n",
            "Epoch 50/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3317\n",
            "Epoch 51/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3249\n",
            "Epoch 52/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3182\n",
            "Epoch 53/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3117\n",
            "Epoch 54/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3052\n",
            "Epoch 55/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2990\n",
            "Epoch 56/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2928\n",
            "Epoch 57/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2868\n",
            "Epoch 58/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2809\n",
            "Epoch 59/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2752\n",
            "Epoch 60/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2695\n",
            "Epoch 61/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2640\n",
            "Epoch 62/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2585\n",
            "Epoch 63/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2532\n",
            "Epoch 64/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2480\n",
            "Epoch 65/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2429\n",
            "Epoch 66/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2379\n",
            "Epoch 67/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2331\n",
            "Epoch 68/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2283\n",
            "Epoch 69/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2236\n",
            "Epoch 70/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2190\n",
            "Epoch 71/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2145\n",
            "Epoch 72/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2101\n",
            "Epoch 73/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2058\n",
            "Epoch 74/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2015\n",
            "Epoch 75/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1974\n",
            "Epoch 76/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1933\n",
            "Epoch 77/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1894\n",
            "Epoch 78/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1855\n",
            "Epoch 79/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1817\n",
            "Epoch 80/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1779\n",
            "Epoch 81/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1743\n",
            "Epoch 82/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1707\n",
            "Epoch 83/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1672\n",
            "Epoch 84/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1638\n",
            "Epoch 85/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1604\n",
            "Epoch 86/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1571\n",
            "Epoch 87/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1539\n",
            "Epoch 88/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1507\n",
            "Epoch 89/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1476\n",
            "Epoch 90/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1446\n",
            "Epoch 91/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1416\n",
            "Epoch 92/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1387\n",
            "Epoch 93/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1359\n",
            "Epoch 94/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1331\n",
            "Epoch 95/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1303\n",
            "Epoch 96/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1277\n",
            "Epoch 97/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1250\n",
            "Epoch 98/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1225\n",
            "Epoch 99/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1200\n",
            "Epoch 100/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1175\n",
            "Epoch 101/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1151\n",
            "Epoch 102/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1127\n",
            "Epoch 103/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1104\n",
            "Epoch 104/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1081\n",
            "Epoch 105/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1059\n",
            "Epoch 106/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1037\n",
            "Epoch 107/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1016\n",
            "Epoch 108/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0995\n",
            "Epoch 109/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0975\n",
            "Epoch 110/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0955\n",
            "Epoch 111/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0935\n",
            "Epoch 112/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0916\n",
            "Epoch 113/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0897\n",
            "Epoch 114/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0879\n",
            "Epoch 115/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0861\n",
            "Epoch 116/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0843\n",
            "Epoch 117/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0826\n",
            "Epoch 118/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0809\n",
            "Epoch 119/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0792\n",
            "Epoch 120/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0776\n",
            "Epoch 121/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0760\n",
            "Epoch 122/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0744\n",
            "Epoch 123/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0729\n",
            "Epoch 124/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0714\n",
            "Epoch 125/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0699\n",
            "Epoch 126/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0685\n",
            "Epoch 127/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0671\n",
            "Epoch 128/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0657\n",
            "Epoch 129/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0644\n",
            "Epoch 130/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0630\n",
            "Epoch 131/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0617\n",
            "Epoch 132/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0605\n",
            "Epoch 133/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0592\n",
            "Epoch 134/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0580\n",
            "Epoch 135/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0568\n",
            "Epoch 136/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0557\n",
            "Epoch 137/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0545\n",
            "Epoch 138/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0534\n",
            "Epoch 139/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0523\n",
            "Epoch 140/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0512\n",
            "Epoch 141/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0502\n",
            "Epoch 142/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0491\n",
            "Epoch 143/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0481\n",
            "Epoch 144/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0471\n",
            "Epoch 145/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0462\n",
            "Epoch 146/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0452\n",
            "Epoch 147/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0443\n",
            "Epoch 148/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0434\n",
            "Epoch 149/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0425\n",
            "Epoch 150/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0416\n",
            "Epoch 151/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0408\n",
            "Epoch 152/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0399\n",
            "Epoch 153/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0391\n",
            "Epoch 154/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0383\n",
            "Epoch 155/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0375\n",
            "Epoch 156/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0367\n",
            "Epoch 157/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0360\n",
            "Epoch 158/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0353\n",
            "Epoch 159/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0345\n",
            "Epoch 160/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0338\n",
            "Epoch 161/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0331\n",
            "Epoch 162/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0324\n",
            "Epoch 163/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0318\n",
            "Epoch 164/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0311\n",
            "Epoch 165/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0305\n",
            "Epoch 166/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0299\n",
            "Epoch 167/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0292\n",
            "Epoch 168/400\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0286\n",
            "Epoch 169/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0281\n",
            "Epoch 170/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0275\n",
            "Epoch 171/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0269\n",
            "Epoch 172/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0264\n",
            "Epoch 173/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0258\n",
            "Epoch 174/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0253\n",
            "Epoch 175/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0248\n",
            "Epoch 176/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0243\n",
            "Epoch 177/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0238\n",
            "Epoch 178/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0233\n",
            "Epoch 179/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0228\n",
            "Epoch 180/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0223\n",
            "Epoch 181/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0219\n",
            "Epoch 182/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0214\n",
            "Epoch 183/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0210\n",
            "Epoch 184/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0206\n",
            "Epoch 185/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0201\n",
            "Epoch 186/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0197\n",
            "Epoch 187/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0193\n",
            "Epoch 188/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0189\n",
            "Epoch 189/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0185\n",
            "Epoch 190/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0181\n",
            "Epoch 191/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0178\n",
            "Epoch 192/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0174\n",
            "Epoch 193/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0171\n",
            "Epoch 194/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0167\n",
            "Epoch 195/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0164\n",
            "Epoch 196/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0160\n",
            "Epoch 197/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0157\n",
            "Epoch 198/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0154\n",
            "Epoch 199/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0151\n",
            "Epoch 200/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0147\n",
            "Epoch 201/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0144\n",
            "Epoch 202/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0141\n",
            "Epoch 203/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0139\n",
            "Epoch 204/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0136\n",
            "Epoch 205/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0133\n",
            "Epoch 206/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0130\n",
            "Epoch 207/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0128\n",
            "Epoch 208/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0125\n",
            "Epoch 209/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0122\n",
            "Epoch 210/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0120\n",
            "Epoch 211/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0117\n",
            "Epoch 212/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0115\n",
            "Epoch 213/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0113\n",
            "Epoch 214/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0110\n",
            "Epoch 215/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0108\n",
            "Epoch 216/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0106\n",
            "Epoch 217/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0104\n",
            "Epoch 218/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0101\n",
            "Epoch 219/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0099\n",
            "Epoch 220/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0097\n",
            "Epoch 221/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0095\n",
            "Epoch 222/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0093\n",
            "Epoch 223/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0091\n",
            "Epoch 224/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0090\n",
            "Epoch 225/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0088\n",
            "Epoch 226/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0086\n",
            "Epoch 227/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0084\n",
            "Epoch 228/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0082\n",
            "Epoch 229/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0081\n",
            "Epoch 230/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0079\n",
            "Epoch 231/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0077\n",
            "Epoch 232/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0076\n",
            "Epoch 233/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0074\n",
            "Epoch 234/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0073\n",
            "Epoch 235/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0071\n",
            "Epoch 236/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0070\n",
            "Epoch 237/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0068\n",
            "Epoch 238/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0067\n",
            "Epoch 239/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0066\n",
            "Epoch 240/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0064\n",
            "Epoch 241/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0063\n",
            "Epoch 242/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0062\n",
            "Epoch 243/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0060\n",
            "Epoch 244/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0059\n",
            "Epoch 245/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0058\n",
            "Epoch 246/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0057\n",
            "Epoch 247/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0056\n",
            "Epoch 248/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0054\n",
            "Epoch 249/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0053\n",
            "Epoch 250/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0052\n",
            "Epoch 251/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0051\n",
            "Epoch 252/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0050\n",
            "Epoch 253/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0049\n",
            "Epoch 254/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0048\n",
            "Epoch 255/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0047\n",
            "Epoch 256/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0046\n",
            "Epoch 257/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0045\n",
            "Epoch 258/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0044\n",
            "Epoch 259/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0043\n",
            "Epoch 260/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0042\n",
            "Epoch 261/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0042\n",
            "Epoch 262/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0041\n",
            "Epoch 263/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0040\n",
            "Epoch 264/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0039\n",
            "Epoch 265/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0038\n",
            "Epoch 266/400\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0037\n",
            "Epoch 267/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0037\n",
            "Epoch 268/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0036\n",
            "Epoch 269/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0035\n",
            "Epoch 270/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0034\n",
            "Epoch 271/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0034\n",
            "Epoch 272/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0033\n",
            "Epoch 273/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0032\n",
            "Epoch 274/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0032\n",
            "Epoch 275/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0031\n",
            "Epoch 276/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0030\n",
            "Epoch 277/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0030\n",
            "Epoch 278/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0029\n",
            "Epoch 279/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0029\n",
            "Epoch 280/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0028\n",
            "Epoch 281/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0027\n",
            "Epoch 282/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0027\n",
            "Epoch 283/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0026\n",
            "Epoch 284/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0026\n",
            "Epoch 285/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0025\n",
            "Epoch 286/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0025\n",
            "Epoch 287/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 288/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0024\n",
            "Epoch 289/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 290/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0023\n",
            "Epoch 291/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0022\n",
            "Epoch 292/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0022\n",
            "Epoch 293/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0021\n",
            "Epoch 294/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0021\n",
            "Epoch 295/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0021\n",
            "Epoch 296/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 297/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0020\n",
            "Epoch 298/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0019\n",
            "Epoch 299/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0019\n",
            "Epoch 300/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0019\n",
            "Epoch 301/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0018\n",
            "Epoch 302/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0018\n",
            "Epoch 303/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0017\n",
            "Epoch 304/400\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0017\n",
            "Epoch 305/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0017\n",
            "Epoch 306/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0016\n",
            "Epoch 307/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0016\n",
            "Epoch 308/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0016\n",
            "Epoch 309/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0015\n",
            "Epoch 310/400\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0015\n",
            "Epoch 311/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0015\n",
            "Epoch 312/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0014\n",
            "Epoch 313/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0014\n",
            "Epoch 314/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0014\n",
            "Epoch 315/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0014\n",
            "Epoch 316/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 317/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0013\n",
            "Epoch 318/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0013\n",
            "Epoch 319/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0012\n",
            "Epoch 320/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0012\n",
            "Epoch 321/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0012\n",
            "Epoch 322/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0012\n",
            "Epoch 323/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 324/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0011\n",
            "Epoch 325/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0011\n",
            "Epoch 326/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0011\n",
            "Epoch 327/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0011\n",
            "Epoch 328/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0010\n",
            "Epoch 329/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0010\n",
            "Epoch 330/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.9286e-04\n",
            "Epoch 331/400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 9.7247e-04\n",
            "Epoch 332/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.5249e-04\n",
            "Epoch 333/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.3293e-04\n",
            "Epoch 334/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.1376e-04\n",
            "Epoch 335/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.9499e-04\n",
            "Epoch 336/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.7661e-04\n",
            "Epoch 337/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5860e-04\n",
            "Epoch 338/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4097e-04\n",
            "Epoch 339/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.2369e-04\n",
            "Epoch 340/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.0677e-04\n",
            "Epoch 341/400\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.9020e-04\n",
            "Epoch 342/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.7397e-04\n",
            "Epoch 343/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.5807e-04\n",
            "Epoch 344/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.4250e-04\n",
            "Epoch 345/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2725e-04\n",
            "Epoch 346/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1231e-04\n",
            "Epoch 347/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9768e-04\n",
            "Epoch 348/400\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8335e-04\n",
            "Epoch 349/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.6931e-04\n",
            "Epoch 350/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.5556e-04\n",
            "Epoch 351/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.4210e-04\n",
            "Epoch 352/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.2891e-04\n",
            "Epoch 353/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.1599e-04\n",
            "Epoch 354/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.0334e-04\n",
            "Epoch 355/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.9095e-04\n",
            "Epoch 356/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.7881e-04\n",
            "Epoch 357/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.6692e-04\n",
            "Epoch 358/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5527e-04\n",
            "Epoch 359/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4387e-04\n",
            "Epoch 360/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3269e-04\n",
            "Epoch 361/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2175e-04\n",
            "Epoch 362/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1104e-04\n",
            "Epoch 363/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.0054e-04\n",
            "Epoch 364/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.9026e-04\n",
            "Epoch 365/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8019e-04\n",
            "Epoch 366/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.7033e-04\n",
            "Epoch 367/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.6066e-04\n",
            "Epoch 368/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.5120e-04\n",
            "Epoch 369/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.4193e-04\n",
            "Epoch 370/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.3285e-04\n",
            "Epoch 371/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.2397e-04\n",
            "Epoch 372/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1526e-04\n",
            "Epoch 373/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0673e-04\n",
            "Epoch 374/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9837e-04\n",
            "Epoch 375/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9019e-04\n",
            "Epoch 376/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8218e-04\n",
            "Epoch 377/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7433e-04\n",
            "Epoch 378/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6664e-04\n",
            "Epoch 379/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5911e-04\n",
            "Epoch 380/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5173e-04\n",
            "Epoch 381/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4450e-04\n",
            "Epoch 382/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3743e-04\n",
            "Epoch 383/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.3050e-04\n",
            "Epoch 384/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2371e-04\n",
            "Epoch 385/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1706e-04\n",
            "Epoch 386/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1055e-04\n",
            "Epoch 387/400\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0417e-04\n",
            "Epoch 388/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9792e-04\n",
            "Epoch 389/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9180e-04\n",
            "Epoch 390/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8581e-04\n",
            "Epoch 391/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7994e-04\n",
            "Epoch 392/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7419e-04\n",
            "Epoch 393/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6856e-04\n",
            "Epoch 394/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6304e-04\n",
            "Epoch 395/400\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5764e-04\n",
            "Epoch 396/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5234e-04\n",
            "Epoch 397/400\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4716e-04\n",
            "Epoch 398/400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4208e-04\n",
            "Epoch 399/400\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3711e-04\n",
            "Epoch 400/400\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3224e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbc920c3fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict([10.0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE0DnqVqGnHs",
        "outputId": "b885d431-6026-4a08-9006-59ec1b7581e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[18.95554]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment_W1"
      ],
      "metadata": {
        "id": "cL6V7aJRMAVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "v-PMj1OAG85G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: house_model\n",
        "def house_model():\n",
        "    ### START CODE HERE\n",
        "    \n",
        "    # Define input and output tensors with the values for houses with 1 up to 6 bedrooms\n",
        "    # Hint: Remember to explictly set the dtype as float\n",
        "    xs = np.array([1,2,3,4,5,6],dtype=float)\n",
        "    ys = np.array([100,150,200,250,300,350],dtype=float)\n",
        "    \n",
        "    # Define your model (should be a model with 1 dense layer and 1 unit)\n",
        "    model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
        "    \n",
        "    # Compile your model\n",
        "    # Set the optimizer to Stochastic Gradient Descent\n",
        "    # and use Mean Squared Error as the loss function\n",
        "    model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "    \n",
        "    # Train your model for 1000 epochs by feeding the i/o tensors\n",
        "    model.fit(xs, ys, epochs=1000)\n",
        "    \n",
        "    ### END CODE HERE\n",
        "    return model"
      ],
      "metadata": {
        "id": "3SOjAKDMMGA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get your trained model\n",
        "model = house_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWjNebwdMMDJ",
        "outputId": "7c357e5a-ff02-4fae-efec-768adbc93d68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 0s 335ms/step - loss: 56333.7344\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 26208.9922\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12265.3623\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5810.8491\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2822.5310\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1438.4772\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 796.9331\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 499.0522\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 360.2353\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 295.0448\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 263.9377\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 248.6125\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 240.5982\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 235.9743\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 232.9265\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 230.6144\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 228.6496\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 226.8521\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 225.1382\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 223.4697\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 221.8286\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 220.2065\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 218.5992\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 217.0053\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 215.4237\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 213.8539\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 212.2958\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 210.7490\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 209.2136\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 207.6894\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 206.1763\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 204.6743\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 203.1830\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 201.7027\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 200.2332\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 198.7744\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 197.3263\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 195.8885\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 194.4616\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 193.0446\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 191.6382\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 190.2420\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 188.8560\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 187.4800\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 186.1142\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 184.7583\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 183.4122\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 182.0759\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 180.7495\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 179.4325\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 178.1254\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 176.8276\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 175.5393\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 174.2602\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 172.9908\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 171.7304\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 170.4793\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 169.2373\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 168.0042\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 166.7803\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 165.5651\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 164.3588\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 163.1614\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 161.9727\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 160.7926\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 159.6212\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 158.4582\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 157.3039\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 156.1578\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 155.0200\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 153.8907\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 152.7694\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 151.6565\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 150.5515\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 149.4547\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 148.3658\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 147.2849\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 146.2119\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 145.1466\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 144.0891\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 143.0395\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 141.9973\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 140.9626\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 139.9358\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 138.9162\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 137.9041\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 136.8994\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 135.9021\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 134.9120\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 133.9290\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 132.9533\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 131.9847\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 131.0230\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 130.0685\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 129.1209\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 128.1802\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 127.2463\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 126.3192\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 125.3989\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 124.4853\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 123.5783\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 122.6781\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 121.7842\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 120.8970\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 120.0162\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 119.1419\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 118.2737\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 117.4121\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 116.5567\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 115.7075\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 114.8645\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 114.0276\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 113.1969\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 112.3723\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 111.5536\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 110.7408\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 109.9339\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 109.1330\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 108.3380\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 107.5486\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 106.7650\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 105.9873\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 105.2151\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 104.4484\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 103.6875\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 102.9321\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 102.1822\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 101.4377\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 100.6987\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 99.9651\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 99.2367\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 98.5138\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 97.7961\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 97.0836\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 96.3763\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 95.6741\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 94.9770\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 94.2851\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 93.5981\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 92.9163\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 92.2392\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 91.5674\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 90.9001\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 90.2378\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 89.5806\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 88.9278\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 88.2799\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 87.6367\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 86.9982\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 86.3644\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 85.7353\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 85.1107\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 84.4906\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 83.8749\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 83.2639\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 82.6573\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 82.0551\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 81.4573\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 80.8637\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 80.2746\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 79.6898\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 79.1093\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 78.5329\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 77.9607\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 77.3928\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 76.8289\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 76.2692\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 75.7135\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 75.1619\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 74.6142\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 74.0706\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 73.5309\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 72.9953\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 72.4635\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 71.9355\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 71.4115\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 70.8912\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 70.3747\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 69.8620\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 69.3531\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 68.8477\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 68.3461\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 67.8482\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 67.3538\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 66.8631\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 66.3760\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 65.8924\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 65.4124\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 64.9359\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 64.4627\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 63.9931\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 63.5268\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 63.0641\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 62.6046\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 62.1485\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 61.6957\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 61.2462\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 60.7999\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 60.3570\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 59.9173\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 59.4808\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 59.0474\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 58.6172\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 58.1901\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 57.7663\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 57.3454\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 56.9276\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 56.5128\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 56.1011\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.6923\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 55.2867\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 54.8838\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 54.4839\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 54.0870\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 53.6930\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 53.3018\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 52.9134\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 52.5279\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 52.1452\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 51.7653\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 51.3882\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 51.0138\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 50.6422\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 50.2731\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 49.9069\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 49.5432\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 49.1823\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 48.8240\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 48.4683\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 48.1152\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 47.7646\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 47.4167\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 47.0711\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 46.7281\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 46.3878\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 46.0499\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 45.7144\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 45.3813\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 45.0507\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.7224\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 44.3966\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 44.0731\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 43.7520\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.4333\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.1169\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.8027\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.4909\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 42.1813\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.8741\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 41.5689\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 41.2661\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.9654\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.6670\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.3706\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 40.0765\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.7845\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.4947\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 39.2070\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 38.9214\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 38.6378\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 38.3562\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 38.0768\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 37.7994\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 37.5241\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 37.2507\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 36.9792\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 36.7098\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 36.4424\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 36.1769\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.9133\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.6517\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.3919\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 35.1340\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 34.8781\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 34.6240\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 34.3718\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 34.1213\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 33.8727\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 33.6259\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 33.3810\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 33.1378\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 32.8964\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 32.6567\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 32.4187\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 32.1826\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 31.9481\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 31.7153\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 31.4842\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 31.2549\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 31.0272\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 30.8011\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 30.5768\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 30.3540\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 30.1328\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 29.9133\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 29.6953\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 29.4790\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 29.2643\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 29.0510\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 28.8394\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 28.6292\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 28.4207\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 28.2136\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 28.0080\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 27.8040\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 27.6014\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 27.4003\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 27.2007\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 27.0025\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 26.8058\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 26.6105\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 26.4166\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 26.2241\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 26.0331\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 25.8434\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 25.6551\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 25.4682\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 25.2827\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 25.0985\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 24.9156\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 24.7341\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 24.5540\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 24.3751\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 24.1975\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 24.0212\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 23.8462\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 23.6724\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 23.4999\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 23.3287\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 23.1588\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 22.9900\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 22.8226\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 22.6563\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 22.4912\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 22.3273\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 22.1647\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 22.0032\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 21.8429\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 21.6837\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 21.5258\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 21.3690\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 21.2133\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 21.0588\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 20.9053\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 20.7530\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 20.6018\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 20.4517\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 20.3027\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 20.1548\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 20.0079\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 19.8622\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 19.7175\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 19.5738\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 19.4312\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 19.2896\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 19.1491\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 19.0096\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 18.8711\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 18.7336\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 18.5971\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 18.4616\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 18.3272\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 18.1936\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 18.0611\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.9295\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 17.7989\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 17.6692\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 17.5405\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 17.4126\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 17.2858\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 17.1599\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 17.0349\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 16.9108\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 16.7875\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 16.6653\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 16.5438\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 16.4232\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 16.3036\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 16.1848\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 16.0669\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 15.9498\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 15.8337\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.7183\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 15.6038\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 15.4901\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 15.3773\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 15.2652\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 15.1540\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 15.0436\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 14.9340\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 14.8252\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 14.7172\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 14.6100\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.5035\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 14.3978\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 14.2930\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 14.1888\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 14.0855\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.9828\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.8810\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 13.7798\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.6794\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 13.5798\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 13.4808\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 13.3827\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.2851\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.1883\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 13.0923\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.9969\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.9022\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.8082\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.7149\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.6223\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.5303\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.4390\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.3483\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.2584\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.1691\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.0804\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.9924\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.9050\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.8183\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.7322\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.6468\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.5619\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.4776\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.3940\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.3110\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.2286\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.1468\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.0656\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.9850\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.9049\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.8255\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.7466\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.6683\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 10.5906\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.5134\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.4369\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.3608\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 10.2853\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.2104\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.1360\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.0621\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.9888\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.9161\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.8438\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.7721\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.7009\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 9.6302\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.5600\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.4904\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.4213\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.3526\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.2845\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.2168\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.1497\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.0830\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.0169\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9511\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.8859\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.8212\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.7569\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6931\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.6298\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5669\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.5045\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4425\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 8.3810\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3200\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 8.2594\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.1992\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.1394\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.0801\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.0213\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.9628\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.9048\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.8472\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.7900\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.7333\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.6769\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.6210\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.5655\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.5104\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.4556\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.4014\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3474\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2939\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2407\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1880\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1356\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0836\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0320\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9808\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9299\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.8794\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8293\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.7796\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.7302\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.6811\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6325\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.5842\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.5362\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.4885\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.4413\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.3944\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.3478\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.3015\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.2556\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.2100\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.1648\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1199\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.0753\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.0310\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.9871\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.9434\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.9002\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.8572\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.8145\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7721\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.7301\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6883\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.6469\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.6058\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.5649\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5244\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.4841\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4442\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4045\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.3651\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3260\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2872\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 5.2487\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2105\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1725\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1348\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0974\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0603\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0234\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.9868\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.9505\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.9144\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8786\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8431\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.8078\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.7728\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.7380\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.7035\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6692\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.6352\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.6014\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.5679\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.5346\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.5016\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.4688\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.4362\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.4039\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.3718\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3400\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3083\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.2770\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.2458\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2149\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.1841\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.1537\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1234\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.0933\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.0635\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.0340\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.0045\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9754\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9464\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9177\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8891\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8608\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8327\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8048\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7770\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7495\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7222\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6951\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6681\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6414\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6149\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.5886\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.5624\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.5365\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.5107\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.4851\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4597\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4345\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4095\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3847\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.3600\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3355\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3112\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.2871\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.2631\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2394\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.2158\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1923\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.1691\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.1460\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1231\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1003\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0777\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0553\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0330\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0109\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9890\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9672\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9456\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9242\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9029\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8817\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8607\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8399\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8192\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.7986\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7783\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.7580\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7379\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7180\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6982\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6785\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6590\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6396\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6204\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6013\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5824\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5636\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.5449\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5263\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5079\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4897\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4715\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4535\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4356\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4179\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4003\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3828\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3654\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3482\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3311\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3141\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2972\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2805\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2639\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2474\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2310\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2148\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1986\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1826\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1667\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1509\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1353\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1197\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1043\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0889\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0737\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0586\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0436\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0287\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0139\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9993\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9847\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9702\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9559\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9416\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9275\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9134\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8995\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8857\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8719\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8583\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8447\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8313\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8180\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8047\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7916\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7785\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7656\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7527\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7399\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7273\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7147\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7022\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6898\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6775\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6652\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6531\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6411\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6291\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6172\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6055\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5938\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5822\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5706\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5592\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5478\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5366\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5253\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5142\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5032\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4922\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4814\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4706\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4599\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4492\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4387\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4282\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4178\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4075\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3972\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3870\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3769\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3669\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3569\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3470\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3372\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3275\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3178\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3082\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2987\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2892\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2799\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2705\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2613\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2521\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2430\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2339\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.2249\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2160\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2071\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1983\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1896\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1809\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1723\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1638\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1553\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1469\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1385\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1302\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1220\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1138\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1057\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0977\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0897\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0817\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0738\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0660\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0583\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0505\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0429\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0353\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0277\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0203\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0128\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0055\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9981\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9908\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9836\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9765\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.9693\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9623\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9553\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9483\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9414\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9345\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9277\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9210\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9143\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9076\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9010\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8944\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.8879\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8814\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8750\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8686\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8623\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.8560\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8498\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8436\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8375\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8314\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8253\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8193\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8133\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8074\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8015\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7957\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7899\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7841\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7784\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7727\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7671\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7615\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7560\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7505\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7450\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7396\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7342\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7288\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7235\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.7183\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7130\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7078\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7027\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6976\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.6925\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6874\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6824\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6774\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6725\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6676\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6627\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6579\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6531\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6484\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6436\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6390\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6343\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6297\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6251\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6205\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6160\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6115\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6071\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6026\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5983\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5939\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5896\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5853\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5810\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5768\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5726\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5684\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5643\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5602\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5561\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5520\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5480\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5440\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5400\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5361\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5322\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5283\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5245\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5207\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5169\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5131\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5094\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5056\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.5020\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4983\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4947\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4911\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4875\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.4840\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4804\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4769\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4734\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4700\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4666\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4632\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4598\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4564\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4531\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4498\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4465\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4433\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4401\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4369\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4337\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4305\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4274\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4243\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4212\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4181\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4151\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4120\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4090\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4060\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4031\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4001\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3972\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3943\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3915\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3886\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.3858\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3830\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3802\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3774\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3747\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3719\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3692\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3665\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3639\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3612\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3586\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3560\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3534\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3508\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3482\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3457\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.3432\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3407\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3382\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3357\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3333\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3309\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3285\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3261\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3237\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3213\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3190\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3167\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3144\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3121\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.3098\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.3075\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.3053\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3031\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3009\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2987\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2965\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2943\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2922\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2901\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2879\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2859\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2838\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2817\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2797\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2776\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2756\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2736\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2716\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2696\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2676\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2657\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2638\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2618\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2599\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2580\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2562\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2543\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2524\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2506\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2488\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2470\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2452\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2434\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2416\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2398\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2381\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2364\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2346\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2329\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2312\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2295\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2279\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2262\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2246\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2229\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2213\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2197\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2181\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.2165\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.2149\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.2134\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2118\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2103\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.2087\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2072\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2057\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2042\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.2027\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2012\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1998\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1983\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1969\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1954\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1940\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1926\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1912\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1898\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1884\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1870\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1857\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1843\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1830\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1817\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1803\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1790\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1777\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1764\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1751\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1739\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1726\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_y = 8.0\n",
        "prediction = model.predict([new_y])[0]\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfX84hUXMN_r",
        "outputId": "4e3a66c9-3d4b-4b33-ea4d-1e491655d909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[450.81964]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "C1W2\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "cnYlHnb8jCT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "5oSNOiBUMQ8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fminst = tf.keras.datasets.fashion_mnist"
      ],
      "metadata": {
        "id": "Mgiw7vO_jNhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(training_images,training_labels),(test_images,test_labels) = fminst.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sn4mRWPjXWp",
        "outputId": "ff37eb96-5fef-4b59-8255-12b5c00a3460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "index = 59\n",
        "\n",
        "np.set_printoptions(linewidth=320)\n",
        "\n",
        "print(f'LABEL: {training_labels[index]}')\n",
        "print(f'\\nIMAGE PIXEL ARRAY:\\n {training_images[index]}')\n",
        "\n",
        "plt.imshow(training_images[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "5k1QHc0bj7NJ",
        "outputId": "15784a25-b6f9-45e4-df76-e6f6a97edd91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL: 3\n",
            "\n",
            "IMAGE PIXEL ARRAY:\n",
            " [[  0   0   0   0   0   0   0   0   0   0   0 112 165 133  67 148 157  56   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 168 229 193 196 194 194 183 237  83   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 155 192 171 176 177 177 166 182  99   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 131 210 168 177 175 177 164 210  64   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 105 233 170 184 182 181 180 212   7   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  25 245 183 181 184 184 193 178   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 228 193 182 185 180 197 108   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 209 200 181 186 179 229  46   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 186 207 180 185 182 225  19   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 195 207 186 188 185 224  20   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 233 200 187 191 183 229  64   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  71 244 183 191 190 181 197 141   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 150 226 185 192 191 185 194 189   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 190 210 193 197 195 190 196 213   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 206 205 194 199 197 192 198 225   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 205 205 199 200 199 198 201 220   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 206 210 202 201 200 199 206 210   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 197 217 203 203 202 201 210 202   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 160 235 200 205 206 202 215 177   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 136 248 198 203 206 200 218 150   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0 115 250 199 203 208 207 217 115   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  95 252 202 205 214 208 217  69   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  38 253 215 211 218 210 216  46   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 255 222 213 215 213 211  22   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 202 226 214 219 212 198   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 180 250 230 237 245 172   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   2 150  82  57 127  23   0   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fce84de0b50>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPdUlEQVR4nO3dfWyd5X3G8es69rFNnEASApGBjJdCNbJODZXJyso6JtaKomkBaUIgrWMdWlBVpHaqpiKmqfzRP9C0tuq0qVtaooa1petEGVHHaFlERZE2hKGBhJcWGgJ5fyEMEkyI7fPbH35ABvzcxz7vzv39SJaPn59vnx9HubjPOfd5ntsRIQAnv0q3GwDQGYQdyARhBzJB2IFMEHYgE/2dvLMBD8aQhjt5l1k4cVb5Y1pZNJUcO3WiL1mvHk3f98TS9GqOXV6vHnZ67Ovj6TvH+xzXGzoRb836wDYVdttXSfqGpD5J346IO1K/P6Rh/Y6vbOYuMYuXb/7d0trQJUeSY1/bdVqyftbP0ve9948nkvWBofL6yMah9NgHHkvfOd7n0dhSWmv4abztPkn/JOlTklZLusH26kb/HoD2auY1+1pJL0TEjog4IekHkta1pi0ArdZM2M+WtGvGz7uLY+9ie73tMdtjE3qribsD0Iy2vxsfERsiYjQiRqsabPfdASjRTNj3SFo14+dzimMAelAzYX9M0kW2z7c9IOl6SZtb0xaAVmt46S0iJm3fIuknml562xgRT7esM7zjyI8/mKz/48X/Ulr7/qHLkmMHz9qZrE9cml6HvzhZlQ4cX1Ja+8o//0dy7F985a+S9dO//T917h0zNbXOHhH3S7q/Rb0AaCM+LgtkgrADmSDsQCYIO5AJwg5kgrADmejo+exozGvH0qeCfvdQ+Smuz716ZnLsUP9ksl5JnI8+F6+On1Jau23ntcmxby1Nn++O+WFmBzJB2IFMEHYgE4QdyARhBzJB2IFMsPS2AEweLF++kqTVH9pbWtt+eCQ5tlJNXx12qpaeD/oqtYbH//6KXyXHbv71byTrmB9mdiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMsE6+wJwyr705Zx/b1H5evU9lUuSY5dU01tyTUZ6PqhF+jTUkVNfL61Vnd5OevFPtqXvO1nFezGzA5kg7EAmCDuQCcIOZIKwA5kg7EAmCDuQCdbZF4Dz/q38fHVJOvezb5bWzhw+lhx7opZewx+opNfCVedqz6cPvlFa+8/9v50cWxnflf7jmJemwm57p6SjkqYkTUbEaCuaAtB6rZjZ/yAiDrfg7wBoI16zA5loNuwh6ae2H7e9frZfsL3e9pjtsQmlP4cNoH2afRp/eUTssX2mpAdtPxcRD8/8hYjYIGmDJJ3q5c1tHAagYU3N7BGxp/h+UNK9kta2oikArddw2G0P217y9m1Jn5S0vVWNAWitZp7Gr5R0r+23/873I+KBlnSFd5ncsTNZ33ZiWWntjMH0OvuB40uS9YrTZ42PTw4k66f0lV+Xfs9Dq5JjV4l19lZqOOwRsUPSh1vYC4A2YukNyARhBzJB2IFMEHYgE4QdyASnuJ4EfvHmeaW1pdXx5Nh9b56arFec/tBj1LmU9LXLx0prv/zZxcmxaC1mdiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMsE6+0ngsf87t7S25rTdybH1tlyuV6/2pS81/UZtsLQ28OLB5NjJZBXzxcwOZIKwA5kg7EAmCDuQCcIOZIKwA5kg7EAmWGc/CaS2Ra5ncTW9JVd/JX0p6XpqqfnEdfZ7RksxswOZIOxAJgg7kAnCDmSCsAOZIOxAJgg7kAnW2U8Cn1nxSGnt31+9NDm23nXhByrps8rrbdm8pPJmae31S89Jjl20e0+yjvmpO7Pb3mj7oO3tM44tt/2g7eeL7+UbhAPoCXN5Gv8dSVe959itkrZExEWSthQ/A+hhdcMeEQ9LOvKew+skbSpub5J0TYv7AtBijb5mXxkR+4rb+yWtLPtF2+slrZekIS1q8O4ANKvpd+MjIiSVvssTERsiYjQiRqsqv/gggPZqNOwHbI9IUvE9fZlQAF3XaNg3S7qxuH2jpPta0w6Adqn7mt323ZKukLTC9m5JX5Z0h6Qf2r5J0kuSrmtnk7k7ev1Hk/Vz+svX2Z8/dmZy7NKB9P7ttUjPB5O1dP3eI6Oltd1Xp8+V/+C9yTLmqW7YI+KGktKVLe4FQBvxcVkgE4QdyARhBzJB2IFMEHYgE5ziugAc+KP05Z6fPLGitNbv9JbKfXVOcZXSy2NDfRPJ+lu18n9il61+ITn2lWQV88XMDmSCsAOZIOxAJgg7kAnCDmSCsAOZIOxAJlhnXwAuu+DFZP2Z42eX1pYNlF/KWZJOqbNOPlHnFNd6p8BWK+Xr/Jct3ZEc+2Nx0eJWYmYHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiATrLMvABcNp/fgODY1VFqrtyVzf2IdXFK909mT6+hS+nz6cwcOpf846+wtxcwOZIKwA5kg7EAmCDuQCcIOZIKwA5kg7EAmWGdfAGpyw2OH+9PXnO+rt5BeZzpY4uPJ+mBlsrR2tHZK+o+jperO7LY32j5oe/uMY7fb3mN7a/F1dXvbBNCsuTyN/46kq2Y5/vWIWFN83d/atgC0Wt2wR8TDko50oBcAbdTMG3S32H6qeJpf+iFm2+ttj9kem1D69SOA9mk07N+U9AFJayTtk/TVsl+MiA0RMRoRo1UNNnh3AJrVUNgj4kBETEVETdK3JK1tbVsAWq2hsNsemfHjtZK2l/0ugN5Qd53d9t2SrpC0wvZuSV+WdIXtNZJC0k5JN7exx+xVlD4nfVFf+Xshx2vV5Nha1FnDjzrr8E7PF4sTve2dWJr+22ipumGPiBtmOXxnG3oB0EZ8XBbIBGEHMkHYgUwQdiAThB3IBKe4LgCHTixJ1i9ZXH7qwqsTw8mxfXVW3qbqLK1VovFlwcMT6f8utBYzO5AJwg5kgrADmSDsQCYIO5AJwg5kgrADmWCdfQF46OULk/XPfOTnpbVnxs9Kjl1c51LTgyq/FLQkjdcGkvUllfJLTT/wym8lx/br5WQd88PMDmSCsAOZIOxAJgg7kAnCDmSCsAOZIOxAJlhnXwDGD6bPSb+gv3wtfCL6kmMnaul6astlSZqspeeLocpEaW3n/tOTYy9knb2lmNmBTBB2IBOEHcgEYQcyQdiBTBB2IBOEHcgE6+wLwMDh9Fp4NXFt94rT13Wvp+qpZH1ZdTxZn4ry3vpfHGqoJzSm7sxue5Xth2w/Y/tp258vji+3/aDt54vvy9rfLoBGzeVp/KSkL0bEakkflfQ526sl3SppS0RcJGlL8TOAHlU37BGxLyKeKG4flfSspLMlrZO0qfi1TZKuaVeTAJo3r9fsts+TdImkRyWtjIh9RWm/pJUlY9ZLWi9JQ1rUaJ8AmjTnd+NtL5Z0j6QvRMTrM2sREZJmfScoIjZExGhEjFY12FSzABo3p7Dbrmo66N+LiB8Vhw/YHinqI5IOtqdFAK1Q92m8bUu6U9KzEfG1GaXNkm6UdEfx/b62dAgNvZLeV7nq8qW5eqeoVivppbXT+tNLa69NNv7SbMW25pYFMT9zec3+MUmflrTN9tbi2G2aDvkPbd8k6SVJ17WnRQCtUDfsEfGIpLKp5crWtgOgXfi4LJAJwg5kgrADmSDsQCYIO5AJTnFdAEZ+/lqyXvnr8v9nnz94KDl2vJb+VONwJb2l83glvWXzVGI+WbS3fDtntB4zO5AJwg5kgrADmSDsQCYIO5AJwg5kgrADmWCdfQGIx59O1lPnsy/vP5YcOzGR/idwvFZN1oecPl/+2FT55aIHdr2SHJv+y5gvZnYgE4QdyARhBzJB2IFMEHYgE4QdyARhBzLBOvtJ4EsH1pTWPr7kueTYimvJ+qI657MfmUqvw+88fnppbfKlXcmxaC1mdiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMjGX/dlXSbpL0kpJIWlDRHzD9u2S/lLS2xcmvy0i7m9Xoyj35Ktnl9b+9oz/TY4d9olkfXlfen/2M+rs//4nu/6stLZYO5Jj0Vpz+VDNpKQvRsQTtpdIetz2g0Xt6xHx9+1rD0CrzGV/9n2S9hW3j9p+VlL5VAKgJ83rNbvt8yRdIunR4tAttp+yvdH2spIx622P2R6bUPqjlwDaZ85ht71Y0j2SvhARr0v6pqQPSFqj6Zn/q7ONi4gNETEaEaNVpfcVA9A+cwq77aqmg/69iPiRJEXEgYiYioiapG9JWtu+NgE0q27YbVvSnZKejYivzTg+MuPXrpW0vfXtAWiVubwb/zFJn5a0zfbW4thtkm6wvUbTy3E7Jd3clg5RV/zh/tLah+/6bHLssofKL/UsSYv3ppfWdn2i/DLWkvSb/7C3tMalojtrLu/GPyLJs5RYUwcWED5BB2SCsAOZIOxAJgg7kAnCDmSCsAOZ4FLSJ4PaVGnpwj/9RVvv+sL/StdZS+8dzOxAJgg7kAnCDmSCsAOZIOxAJgg7kAnCDmTCEdG5O7MPSXppxqEVkg53rIH56dXeerUvid4a1crezo2IM2YrdDTs77tzeywiRrvWQEKv9tarfUn01qhO9cbTeCAThB3IRLfDvqHL95/Sq731al8SvTWqI7119TU7gM7p9swOoEMIO5CJroTd9lW2f2n7Bdu3dqOHMrZ32t5me6vtsS73stH2QdvbZxxbbvtB288X32fdY69Lvd1ue0/x2G21fXWXeltl+yHbz9h+2vbni+NdfewSfXXkcev4a3bbfZJ+JekTknZLekzSDRHxTEcbKWF7p6TRiOj6BzBsf1zSMUl3RcSHimN/J+lIRNxR/I9yWUR8qUd6u13SsW5v413sVjQyc5txSddI+nN18bFL9HWdOvC4dWNmXyvphYjYEREnJP1A0rou9NHzIuJhSUfec3idpE3F7U2a/sfScSW99YSI2BcRTxS3j0p6e5vxrj52ib46ohthP1vSrhk/71Zv7fcekn5q+3Hb67vdzCxWRsS+4vZ+SSu72cws6m7j3Unv2Wa8Zx67RrY/bxZv0L3f5RHxEUmfkvS54ulqT4rp12C9tHY6p228O2WWbcbf0c3HrtHtz5vVjbDvkbRqxs/nFMd6QkTsKb4flHSvem8r6gNv76BbfD/Y5X7e0UvbeM+2zbh64LHr5vbn3Qj7Y5Iusn2+7QFJ10va3IU+3sf2cPHGiWwPS/qkem8r6s2Sbixu3yjpvi728i69so132Tbj6vJj1/XtzyOi41+Srtb0O/K/lvQ33eihpK8LJD1ZfD3d7d4k3a3pp3UTmn5v4yZJp0vaIul5Sf8taXkP9favkrZJekrTwRrpUm+Xa/op+lOSthZfV3f7sUv01ZHHjY/LApngDTogE4QdyARhBzJB2IFMEHYgE4QdyARhBzLx/2hYf2ve2/guAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_images= training_images/255.0\n",
        "test_images= test_images/255.0"
      ],
      "metadata": {
        "id": "RZpZugWGkLua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "                             tf.keras.layers.Flatten(),\n",
        "                             tf.keras.layers.Dense(128,activation=tf.nn.relu),\n",
        "                             tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "])"
      ],
      "metadata": {
        "id": "zrBi0a11k4aB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare sample inputs and convert to a tensor\n",
        "inputs = np.array([[1.0, 3.0, 4.0, 2.0]])\n",
        "inputs = tf.convert_to_tensor(inputs)\n",
        "print(f'input to softmax function: {inputs.numpy()}')\n",
        "\n",
        "# Feed the inputs to a softmax activation function\n",
        "outputs = tf.keras.activations.softmax(inputs)\n",
        "print(f'output of softmax function: {outputs.numpy()}')\n",
        "\n",
        "# Get the sum of all values after the softmax\n",
        "sum = tf.reduce_sum(outputs)\n",
        "print(f'sum of outputs: {sum}')\n",
        "\n",
        "# Get the index with highest value\n",
        "prediction = np.argmax(outputs)\n",
        "print(f'class with highest probability: {prediction}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2-PeU0cmiUL",
        "outputId": "80c90820-ea73-4302-d6ea-9103d767e7ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input to softmax function: [[1. 3. 4. 2.]]\n",
            "output of softmax function: [[0.0320586  0.23688282 0.64391426 0.08714432]]\n",
            "sum of outputs: 1.0\n",
            "class with highest probability: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(training_images,training_labels,epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qW4SE9Nzmjrb",
        "outputId": "26be0a98-7aa3-47f3-ae76-509d31395404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2320 - accuracy: 0.9132\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2226 - accuracy: 0.9162\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2136 - accuracy: 0.9203\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2088 - accuracy: 0.9211\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2035 - accuracy: 0.9236\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce7f4d7450>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_images,test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toihYvZvndcA",
        "outputId": "2beea679-88f5-496e-ca7f-5410aa2b83f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3450 - accuracy: 0.8827\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3449919819831848, 0.8827000260353088]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f09hNRrUoYBV",
        "outputId": "fbb281b1-22e5-4320-a291-e5c4d2d191d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6.5316073e-07 7.9429241e-10 9.0761926e-10 2.8797898e-13 7.1441955e-09 3.0353179e-04 6.0799654e-10 5.3855998e-04 4.2985812e-10 9.9915731e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqA6Nfq-qPVt",
        "outputId": "68ff96f9-116c-426d-fb9e-c926a521088d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#increase to 1024 neurons\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu), # Try experimenting with this layer\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjjRaiQNqSJF",
        "outputId": "f4a74d4f-0de4-4d6a-f1d9-fccb20fa48ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 18s 9ms/step - loss: 0.1823\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0721\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 19s 10ms/step - loss: 0.0487\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0352\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0250\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0603\n",
            "[2.2759830e-08 1.5136140e-09 1.9738256e-07 6.4287849e-07 1.0429170e-13 3.1460726e-10 5.2828476e-14 9.9999785e-01 7.9805529e-10 1.2707078e-06]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#what-if we remove flatten()\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([#Try removing this layer\n",
        "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "S1ImuGXyrSaa",
        "outputId": "8a885de4-1c8a-4f95-f43f-23271a516d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-6b732f5b001f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m               loss = 'sparse_categorical_crossentropy')\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1863, in sparse_categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5203, in sparse_categorical_crossentropy\n        labels=target, logits=output)\n\n    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(32,) and logits.shape=(896, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#changing 3rd layer output nuerons number\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(1, activation=tf.nn.softmax) # Try experimenting with this layer\n",
        "                                  ])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=1)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7hYGxB4qrXi-",
        "outputId": "95a05609-c834-45d8-ac56-1a5d335d5f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-9c3d5c3a9270>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m               loss = 'sparse_categorical_crossentropy')\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-31-9c3d5c3a9270>\", line 16, in <module>\n      model.fit(training_images, training_labels, epochs=1)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n      y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1863, in sparse_categorical_crossentropy\n      y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5203, in sparse_categorical_crossentropy\n      labels=target, logits=output)\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of 9 which is outside the valid range of [0, 1).  Label values: 3 3 9 4 7 8 4 1 6 2 7 4 6 3 7 3 4 6 2 3 7 1 9 6 8 2 7 6 8 6 3 9\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_266950]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#whatif we added extra layers\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    # Add a layer here,\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    # Add a layer here\n",
        "                                  ])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "id": "hSaCZQzwrYTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#what if epoch number is changed\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5) # Experiment with the number of epochs\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[34])\n",
        "print(test_labels[34])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW7jSOa-rbtV",
        "outputId": "c91951c6-b231-4b58-c2db-64f49a1b3cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.6771\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.3729\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2827\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2544\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2327\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2305\n",
            "[4.7865970e-28 1.6218213e-10 4.0525677e-12 3.0937568e-09 3.8549140e-25 0.0000000e+00 0.0000000e+00 1.0000000e+00 4.7289792e-18 6.1908997e-18]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if images were given in 0-255 rather than 0-1\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "# training_images=training_images/255.0  Experiment with removing this line\n",
        "# test_images=test_images/255.0  Experiment with removing this line\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6TyagIQreW9",
        "outputId": "fee45a51-3f08-42a2-a0da-61499ca5edd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.7573\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3528\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3109\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2845\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2593\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.2878\n",
            "[3.4745903e-21 1.3936082e-33 8.9355576e-19 4.5944250e-18 2.8245912e-24 1.0791835e-18 0.0000000e+00 1.0000000e+00 2.7545088e-26 3.8485822e-17]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating callback function to reduce execution time\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('loss') < 0.4): # Experiment with changing this value\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qhyVLI4rgsk",
        "outputId": "3394732c-9224-482f-dec1-7ed7568a3dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4735 - accuracy: 0.8303\n",
            "Epoch 2/5\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 0.3583 - accuracy: 0.8684\n",
            "Reached 60% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3583 - accuracy: 0.8684\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fce6d394a10>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment_W2"
      ],
      "metadata": {
        "id": "fZAk-JZhtw6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "x18Axj_NtKAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "fminst = tf.keras.datasets.fashion_mnist\n",
        "# Get current working directory\n",
        "current_dir = os.getcwd()\n",
        "\n",
        "# Append data/mnist.npz to the previous path to get the full path\n",
        "data_path = os.path.join(current_dir, \"data/mnist.npz\")\n",
        "\n",
        "# Discard test set\n",
        "(x_train, y_train), (x_test,y_test) = tf.keras.datasets.mnist.load_data()\n",
        "        \n",
        "# Normalize pixel values\n",
        "x_train = x_train / 255.0"
      ],
      "metadata": {
        "id": "5irWeLedxwGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_shape = x_train.shape\n",
        "\n",
        "print(f\"There are {data_shape[0]} examples with shape ({data_shape[1]}, {data_shape[2]})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-pmj6hhxwls",
        "outputId": "adb21805-cd6c-4f64-fead-1ea3174bfa47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 60000 examples with shape (28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED CLASS: myCallback\n",
        "### START CODE HERE\n",
        "# callbacks= myCallback()\n",
        "\n",
        "# Remember to inherit from the correct class\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "        # Define the correct function signature for on_epoch_end\n",
        "        def on_epoch_end(self, epoch, logs={}):\n",
        "            if logs.get('accuracy') > 0.99: \n",
        "                print(\"\\nReached 99% accuracy so cancelling training!\") \n",
        "                \n",
        "                # Stop training once the above condition is met\n",
        "                self.model.stop_training = True\n",
        "\n",
        "### END CODE HERE"
      ],
      "metadata": {
        "id": "C3zdRBCzx_N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: train_mnist\n",
        "def train_mnist(x_train, y_train):\n",
        "\n",
        "    ### START CODE HERE\n",
        "    \n",
        "    # Instantiate the callback class\n",
        "    callbacks = myCallback()\n",
        "    \n",
        "    # Define the model, it should have 3 layers:\n",
        "    # - A Flatten layer that receives inputs with the same shape as the images\n",
        "    # - A Dense layer with 512 units and ReLU activation function\n",
        "    # - A Dense layer with 10 units and softmax activation function\n",
        "    model = tf.keras.models.Sequential([ \n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512,activation=tf.nn.relu),\n",
        "        tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "    ]) \n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', \n",
        "                  loss='sparse_categorical_crossentropy', \n",
        "                  metrics=['accuracy']) \n",
        "    \n",
        "    # Fit the model for 10 epochs adding the callbacks\n",
        "    # and save the training history\n",
        "    history = model.fit(x_train, y_train, epochs=10, callbacks=[callbacks])\n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "FcY8kNbHyBj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = train_mnist(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZvUt3ChyG-z",
        "outputId": "1c49fe65-9a3c-42cc-bcc6-b7630871e626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.2034 - accuracy: 0.9413\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0816 - accuracy: 0.9754\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0524 - accuracy: 0.9832\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0360 - accuracy: 0.9891\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - ETA: 0s - loss: 0.0278 - accuracy: 0.9908\n",
            "Reached 99% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0278 - accuracy: 0.9908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "C1W3\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NU4uSe2E2d0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
        "\n",
        "# Normalize the pixel values\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# Setup training parameters\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "print(f'\\nMODEL TRAINING:')\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "# Evaluate on the test set\n",
        "print(f'\\nMODEL EVALUATION:')\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "UHbip3VlyJLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1df572eb-9ab4-4cad-e6b7-7635a4b6de78"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MODEL TRAINING:\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.5033 - accuracy: 0.8240\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3740 - accuracy: 0.8668\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3385 - accuracy: 0.8768\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3127 - accuracy: 0.8855\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2956 - accuracy: 0.8914\n",
            "\n",
            "MODEL EVALUATION:\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3979 - accuracy: 0.8559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Conv2D(32,(3,3),activation='relu', input_shape=(28,28,1)),\n",
        "                                    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "                                    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                    tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# Setup training parameters\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "print(f'\\nMODEL TRAINING:')\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "# Evaluate on the test set\n",
        "print(f'\\nMODEL EVALUATION:')\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yIbD9WTlgZu",
        "outputId": "6dda48ff-7a3c-43a6-e064-af7df1279107"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MODEL TRAINING:\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.4600 - accuracy: 0.8339\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.3140 - accuracy: 0.8847\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.2672 - accuracy: 0.9007\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.2378 - accuracy: 0.9116\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.2155 - accuracy: 0.9189\n",
            "\n",
            "MODEL EVALUATION:\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2526 - accuracy: 0.9098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment_W3"
      ],
      "metadata": {
        "id": "pKWtKteo5P__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load the data\n",
        "\n",
        "# Get current working directory\n",
        "current_dir = os.getcwd() \n",
        "\n",
        "# Append data/mnist.npz to the previous path to get the full path\n",
        "data_path = os.path.join(current_dir, \"data/mnist.npz\") \n",
        "\n",
        "# Get only training set\n",
        "(training_images, training_labels), (test_images,test_labels) = tf.keras.datasets.mnist.load_data(path=data_path) \n",
        "\n",
        "# GRADED FUNCTION: reshape_and_normalize\n",
        "\n",
        "def reshape_and_normalize(images):\n",
        "    \n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Reshape the images to add an extra dimension\n",
        "    images = images.reshape((60000,28,28,-1))\n",
        "    \n",
        "    # Normalize pixel values\n",
        "    images = images/255.0\n",
        "    \n",
        "    ### END CODE HERE\n",
        "\n",
        "    return images\n",
        "\n",
        "# Reload the images in case you run this cell multiple times\n",
        "(training_images, training_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data(path=data_path) \n",
        "\n",
        "# Apply your function\n",
        "training_images = reshape_and_normalize(training_images)\n",
        "\n",
        "print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n",
        "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
        "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")\n",
        "\n",
        "# GRADED CLASS: myCallback\n",
        "### START CODE HERE\n",
        "\n",
        "# Remember to inherit from the correct class\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "      def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy') > 0.995):\n",
        "            print(\"\\nReached 99.5% accuracy so cancelling training!\")\n",
        "            self.model.stop_training = True\n",
        "    # Define the method that checks the accuracy at the end of each epoch\n",
        "\n",
        "### END CODE HERE\n",
        "\n",
        "\n",
        "# GRADED FUNCTION: convolutional_model\n",
        "def convolutional_model():\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Define the model, it should have 5 layers:\n",
        "    # - A Conv2D layer with 32 filters, a kernel_size of 3x3, ReLU activation function\n",
        "    #    and an input shape that matches that of every image in the training set\n",
        "    # - A MaxPooling2D layer with a pool_size of 2x2\n",
        "    # - A Flatten layer with no arguments\n",
        "    # - A Dense layer with 128 units and ReLU activation function\n",
        "    # - A Dense layer with 10 units and softmax activation function\n",
        "    model = tf.keras.models.Sequential([ \n",
        "      tf.keras.layers.Conv2D(32,(3,3),activation='relu', input_shape=(28,28,1)),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "      tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "    ]) \n",
        "\n",
        "    ### END CODE HERE\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', \n",
        "                  loss='sparse_categorical_crossentropy', \n",
        "                  metrics=['accuracy']) \n",
        "        \n",
        "    return model\n",
        "\n",
        "# Save your untrained model\n",
        "model = convolutional_model()\n",
        "\n",
        "# Instantiate the callback classii\n",
        "callbacks = myCallback()\n",
        "\n",
        "# Train your model (this can take up to 5 minutes)\n",
        "history = model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])\n",
        "\n",
        "\n",
        "print(f\"Your model was trained for {len(history.epoch)} epochs\")"
      ],
      "metadata": {
        "id": "qXy_bXfsrZjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jdfYfT5C5Tes"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}